{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# What we want to learn today? \n",
    "Today we will have a first look at the Convokit toolkit for conversational analysis. The toolkit is designed to provide a unified framework to load and work with interactive conversational data. It already comes with a larger amount of existing conversational datasets, and it also provides a set of tools to manipulate, analyze, and model conversational data. \n",
    "\n",
    "In the session today we will look at two dataset that have annotations for two of the pragmatic phenomena we talked about in the first lecture: politeness strategies and speech acts. The website for Convokit is here: https://convokit.cornell.edu/\n",
    "\n",
    "What we will cover today:\n",
    "- representation of datasets: the corpus object in Convokit, how to load and extract information from it?\n",
    "- manipulation of data: How to use the Transformation Pipeline (e.g., filtering, adding annotations, extracting linguistic features)?\n",
    "- How to train a simple feature-based classifier to predict politeness strategies or speech acts in the conversations?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5380a38710beebb2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from convokit import Corpus, download, TextParser, PolitenessStrategies, Classifier, BoWTransformer\n",
    "import random"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b38acc8b382dca34",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# we are first going to download the two corpora we will be using today.\n",
    "# 1) The Stanford Politeness Corpus (Danescu-Niculescu-Mizil et al., 2013), which contains ~10k posts from Stack Exchange annotated for politeness strategies.\n",
    "pol_corpus = Corpus(filename=download(\"wikipedia-politeness-corpus\"))\n",
    "# 2) The Switchboard Corpus (Godfrey et al., 1992), which contains ~1k two-sided telephone conversations annotated for speech acts.\n",
    "#swbd_corpus = Corpus(filename=download(\"switchboard-processed-corpus\"))\n",
    "swbd_corpus = Corpus(filename=download(\"switchboard-corpus\"))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "97f943cf8697fdbf",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you want to learn more about the two corpora, you can check out the following links:\n",
    "- Stanford Politeness Corpus: https://www.cs.cornell.edu/~cristian//pdfs/politeness_talk.pdf\n",
    "- and the paper: https://aclanthology.org/P13-1025.pdf\n",
    "- Switchboard Corpus: https://web.stanford.edu/~jurafsky/tr.pdf\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72b3b2a9da3b4c0f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Let's take a look at the summary statistics of the two corpora.\n",
    "pol_corpus.print_summary_stats()\n",
    "swbd_corpus.print_summary_stats()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65527609129d49b2",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Each corpus component has a consistent data format and we have three core components / objects:\n",
    "- the utterance object: represents a single utterance in a conversation. It has primary data fields such as text, id, speaker, conversation_id (the conversation it belongs to), reply_to (the utterance it is replying to, if any), and metadata attributes such as annotations or additional features (e.g. dependency parse trees, sentiment scores, etc.).\n",
    "- to access a random utterance from the corpus, we can use the .random_utterance() method.\n",
    "- to access a specific utterance by its ID, we can use the .get_utterance(utterance_id) method.\n",
    "- we can also iterate through all utterances in the corpus using the .iter_utterances() method.\n",
    "--> task: retrieve a random utterance from the politeness corpus and the switchboard corpus and look at its text, speaker, and metadata,\n",
    "--> what differences do you notice between the two corpora?\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43ae08ba20d788fe"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# we can also get all utterances of a corpus as a dataframe. \n",
    "utt_df_pol = pol_corpus.get_utterances_dataframe()\n",
    "utt_df_swbd = swbd_corpus.get_utterances_dataframe()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9478378190c07071",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "utt_df_pol.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95e7be88ca0a6ca7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "utt_df_swbd.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5045d997e01f7369",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "- the speaker object: represents a single speaker in a conversation. It has primary data fields such as id, and metadata attributes such as demographic information or other speaker-level annotations.\n",
    "--> task: retrieve a random speaker from the politeness corpus and the switchboard corpus and look at its id, and metadata.\n",
    "--> what differences do you notice between the two corpora?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30e8c72a07f9e749"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# again we can retrieve all speakers as a dataframe.\n",
    "speaker_df_pol = pol_corpus.get_speakers_dataframe()\n",
    "speaker_df_swbd = swbd_corpus.get_speakers_dataframe()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b7ca09f6d1fe705",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "speaker_df_pol.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48657dec24fcf195",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "speaker_df_swbd.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a0deff068d6472f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "- the third core object is the conversation object: it represents a single conversation / interaction. It has primary data fields such as id, owner (which corpus does it belong to?) and metadata attributes such as topic or other conversation-level annotations.\n",
    "- to access a random conversation from the corpus, we can use the .random_conversation() method.\n",
    "- to access a specific conversation by its ID, we can use the .get_conversation(conversation_id) method.\n",
    "- we can also iterate through all conversations in the corpus using the .iter_conversations() method.\n",
    "- we can also get all conversations of a corpus as a dataframe with the .get_conversations_dataframe() method.\n",
    "--> task: retrieve a random conversation from the politeness corpus and the switchboard corpus and look at its primary data fields and metadata and compare them."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16cd6c6902d5f53b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "convo_df_pol = pol_corpus.get_conversations_dataframe()\n",
    "convo_df_swbd = swbd_corpus.get_conversations_dataframe()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c6314ba71f9590f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "convo_df_pol.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5edac5707bd116b6",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "To summarize: every corpus in Convokit is made up of conversations, that contain utterances, which are produced by speakers. For each component we can access the corresponding connected components, such as speaker of an utterance, conversation of an utterance, utterances in a conversation, etc."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1679ef9c5b1d1b82"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "convo_df_swbd.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8135a94e8d0bffbd",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the politeness corpus we have annotated politeness labels, stored in the utterance metadata. Take a look at the distribution of politeness labels in the corpus. The binarized politeness label (\"Binary\") indicates 1=”polite”, 0=”neutral”, -1 = “impolite”. The continuous politeness score (\"PolitenessScore\") is a continuous score ranging from -3 (most impolite) to 3 (most polite).\n",
    "--> task: check the distribution of the labels (e.g. histogram plot or value counts) for both the binary and continuous politeness labels."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2aecd6e13bc87a20"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we will look into how to use different transformers to manipulate and analyze the corpus data. \n",
    "Next, we will use the built-in PolitenessStrategies transformer to extract politeness strategies from the utterance text and add them as features to the utterance metadata. The extractor uses pattern-matching rules over syntactic parses to detect linguistic indicators of politeness. How can we use and transform an extractor in Convokit?\n",
    "1) First, we need to initialize the transformer object: pol_strategies = PolitenessStrategies()\n",
    "2) Then, we can apply the transformer to the corpus using the .transform() method: pol_corpus = pol_strategies.transform(pol_corpus)\n",
    "3) Finally, we can access the extracted features in the utterance metadata. The extracted politeness strategies are stored in the 'politeness_strategies' field of the utterance metadata as a dictionary, where keys are strategy names and values are lists of tuples containing the span indices and corresponding text tokens, if markers == True, otherwise only counts are stored.\n",
    "4) we can also use the summarize() method of pol_strategies to get an overview of the extracted politeness strategies. (and use plot=True to visualize the distribution of strategies)\n",
    "--> task: follow the steps above to extract politeness strategies from the politeness corpus and display the first few utterances with their extracted strategies, then use the summarize() method to visualize the distribution of strategies."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6f06902f975062b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "For a short / rough overview of the politeness strategies in this corpus: \n",
    "\n",
    "| Strategy                | Linguistic Pattern (simplified)      | Example                       |\n",
    "|--------------------------|--------------------------------------|--------------------------------|\n",
    "| **Apology**              | regex for “sorry”, “apologize”, etc. | “I’m sorry to ask, but…”       |\n",
    "| **Gratitude**            | tokens like “thanks”, “thank you”    | “Thanks for your help!”        |\n",
    "| **Deference**            | honorifics like “sir”, “ma’am”       | “Yes, sir.”                    |\n",
    "| **Indirect Request**     | modal verbs “could”, “would” + verb  | “Could you check this?”        |\n",
    "| **Please**               | token “please” anywhere              | “Please have a look.”          |\n",
    "| **Hedges**               | “maybe”, “I think”, “sort of”        | “I think you might be right.”  |\n",
    "| **First Person Plural**  | use of “we”, “our” for solidarity    | “We should try again.”         |\n",
    "| **Compliment**           | “good job”, “nice work”, etc.        | “Great answer!”                |\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "979f98984ffc742f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pol_strategies = PolitenessStrategies()\n",
    "pol_corpus = pol_strategies.transform(pol_corpus, markers=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "462e9a30f924f586",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_pol = pol_corpus.get_utterances_dataframe()\n",
    "df_pol.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9fb305dac777f51d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can visualize the tokens that correspond to the features with the following code. This code shows a random utterance and features highlighted / color-coded."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f33c6d181e01cf2f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import re\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def highlight_politeness_markers(utterance):\n",
    "    \"\"\"\n",
    "    Visualize politeness markers in an utterance.\n",
    "    \"\"\"\n",
    "    text = utterance.text\n",
    "    markers = utterance.meta.get('politeness_markers', {})\n",
    "\n",
    "    # Collect all tokens to highlight\n",
    "    highlight_spans = []\n",
    "    for key, token_lists in markers.items():\n",
    "        if not token_lists:\n",
    "            continue\n",
    "        strategy = key.replace('politeness_markers_==', '').replace('==', '')\n",
    "        for token_group in token_lists:\n",
    "            for token, sent_i, tok_i in token_group:\n",
    "                highlight_spans.append((token, strategy))\n",
    "\n",
    "    if not highlight_spans:\n",
    "        print(\"No politeness markers detected for this utterance.\")\n",
    "        print(utterance.text)\n",
    "        return\n",
    "\n",
    "    colors = [\n",
    "        \"#FFD54F\", \"#AED581\", \"#81D4FA\", \"#CE93D8\",\n",
    "        \"#FFAB91\", \"#C5E1A5\", \"#F48FB1\", \"#80CBC4\",\n",
    "        \"#E6EE9C\", \"#B39DDB\"\n",
    "    ]\n",
    "    color_map = {}\n",
    "    color_index = 0\n",
    "\n",
    "    def get_color(strategy):\n",
    "        nonlocal color_index\n",
    "        if strategy not in color_map:\n",
    "            color_map[strategy] = colors[color_index % len(colors)]\n",
    "            color_index += 1\n",
    "        return color_map[strategy]\n",
    "\n",
    "    highlighted_text = text\n",
    "    for token, strategy in highlight_spans:\n",
    "        color = get_color(strategy)\n",
    "        pattern = r'\\b' + re.escape(token) + r'\\b'\n",
    "        repl = f\"<mark style='background-color:{color};' title='{strategy}'>{token}</mark>\"\n",
    "        highlighted_text = re.sub(pattern, repl, highlighted_text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Create color-coded legend\n",
    "    legend_html = \"<div style='margin-top:10px;'>\"\n",
    "    for strategy, color in color_map.items():\n",
    "        legend_html += f\"<span style='background-color:{color}; padding:2px 6px; border-radius:4px; margin-right:4px;'>{strategy}</span>\"\n",
    "    legend_html += \"</div>\"\n",
    "\n",
    "    # Display the highlighted text + legend\n",
    "    html = f\"\"\"\n",
    "    <div style='font-family:sans-serif; line-height:1.6;'>\n",
    "        <p>{highlighted_text}</p>\n",
    "        {legend_html}\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(html))\n",
    "\n",
    "    #print(\"Detected strategies:\", sorted(set([s for _, s in highlight_spans])))\n",
    "\n",
    "u = list(pol_corpus.iter_utterances())[random.randint(0, len(pol_corpus.utterances) - 1)]\n",
    "highlight_politeness_markers(u)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2122ef14c85a139b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have extracted politeness strategies as features, we can use them to train a simple classifier to predict whether an utterance is polite or not. We will use the built-in Classifier module in Convokit for this purpose. We will use the extracted politeness strategies as features and the binary politeness label as the target variable."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad9a22411682a0ef"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.metrics import classification_report\n",
    "from convokit import Classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a99762e481cf9e05",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pol_binary_corpus = Corpus(utterances=[utt for utt in pol_corpus.iter_utterances() if utt.meta[\"Binary\"] != 0])\n",
    "# check the distribution\n",
    "utt_new = pol_binary_corpus.random_utterance()\n",
    "utt_df_binary = pol_binary_corpus.get_utterances_dataframe()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfc72f4559b3a40b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The Classifier object:\n",
    "- obj_type: specifies the type of object to classify (utterance, speaker, conversation)\n",
    "- labeller: a function that takes an object and returns its label (in this case we want to use the .meta info of the utterance to get the binary politeness label)\n",
    "- you can then use the functions .evaluate_with_cv() to get results on a 5-fold cross validation\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10686f29e40a37ef"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# this code uses the wrapper from convokit\n",
    "cv_classifier = Classifier(\n",
    "    obj_type='utterance', pred_feats=['politeness_strategies'],\n",
    "    labeller=lambda u: u.meta['Binary'] == 1)\n",
    "\n",
    "cv_results = cv_classifier.evaluate_with_cv(pol_binary_corpus, selector=lambda u: u.meta.get('Binary') in {1, -1})\n",
    "print(\"Cross-validation accuracy per fold:\", cv_results)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e0c57441ea9d853",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# here we use the full corpus, train and predict\n",
    "cv_classifier.fit_transform(corpus=pol_binary_corpus, selector=lambda u: u.meta.get('Binary') in {1, -1})\n",
    "result_df = cv_classifier.summarize(pol_binary_corpus)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3a59070865f4f4d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since we used a LogisticRegression Classifier we can directly inspect which features where most impactful. \n",
    "--> Look at the 10 \"most polite\" and 10 \"most impolite\" indicators."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0865b61289e4e5f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "feature_names = sorted(list(next(iter(pol_binary_corpus.iter_utterances())).meta['politeness_strategies'].keys()))\n",
    "\n",
    "coefs = cv_classifier.clf.named_steps['logreg'].coef_[0]\n",
    "\n",
    "coef_df = pd.DataFrame({'Feature': feature_names, 'Weight': coefs})\n",
    "coef_df = coef_df.sort_values('Weight', ascending=False)\n",
    "display(coef_df.head(10))      # Most \"polite\" indicators\n",
    "display(coef_df.tail(10))      # Most \"impolite\" indicators"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f433b4c56771ec55",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "An alternative solution is to not use the built-in wrapper of convokit but to use the sckit-learn classifier explicitly. Then you have more options to adapt the models to your use cases. For that you need to create the feature vectors from the meta data when iterating over the corpus. The label you can get with utterance.meta.get('Binary'). You can iterate over corpus utterances with .iter_utterances()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd39d832b834662b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, let's have a look at speech acts. We will look at the switchboard corpus. We have to use a different version of the corpus for being able to use the speech acts. In this corpus, since it captures dialogues, the concept is called \"dialogue acts\".\n",
    "--> check how these are annotated in the dataset, the labels are stored in the \"tags\" field in the metadata. Inspect a few random utterances. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d77057fbd73df2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "swbd_corpus = Corpus(filename=download(\"switchboard-processed-corpus\"))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f736a47ee92fabbe",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "For your reference, here is a table with the DMSL tags used in the Switchboard corpus, the full name of the tag and an example.\n",
    "--> In what way do they differ from the speech acts we have looked at in the lecture?\n",
    "\n",
    "| DAMSL Tag | Dialogue / Speech Act Label          | Example Utterance                          |\n",
    "|------------|--------------------------------------|--------------------------------------------|\n",
    "| **sd**     | Statement-non-opinion               | “It’s raining outside.”                    |\n",
    "| **sv**     | Statement-opinion                   | “I think that’s a bad idea.”               |\n",
    "| **b**      | Acknowledge / Backchannel           | “Uh-huh.” / “Right.”                       |\n",
    "| **aa**     | Agree / Accept                      | “Yes.” / “Exactly.”                        |\n",
    "| **ba**     | Appreciative                        | “Thanks a lot!”                            |\n",
    "| **qy**     | Yes-No Question                     | “Do you like pizza?”                       |\n",
    "| **qw**     | Wh-Question                         | “What time is it?”                         |\n",
    "| **qo**     | Open Question                       | “How do you feel about that?”              |\n",
    "| **qr**     | Or-Question                         | “Is it red or blue?”                       |\n",
    "| **qyd**    | Declarative Yes-No Question         | “You’re coming tonight?”                   |\n",
    "| **ny**     | Yes Answer                          | “Yes.” / “I do.”                           |\n",
    "| **nn**     | No Answer                           | “No.” / “I don’t.”                         |\n",
    "| **fc**     | Conventional Closing                | “Goodbye.” / “See you later.”              |\n",
    "| **fp**     | Conventional Opening                | “Hi!” / “Hello!”                           |\n",
    "| **fe**     | Exclamation                         | “Wow!” / “Great!”                          |\n",
    "| **ft**     | Thanking                            | “Thanks!” / “Thank you so much.”           |\n",
    "| **fa**     | Apology                             | “Sorry about that.”                        |\n",
    "| **fo**     | Offer / Invitation                  | “Would you like some coffee?”              |\n",
    "| **oo**     | Other Answers                       | “Maybe.” / “Could be.”                     |\n",
    "| **h**      | Hedge / Qualified Answer            | “I guess so.” / “Probably.”                |\n",
    "| **na**     | Affirmative Non-Yes Answer          | “Yeah, sure.” / “Absolutely.”              |\n",
    "| **ng**     | Negative Non-No Answer              | “Nope, not really.”                        |\n",
    "| **arp**    | Repetition Request                  | “Pardon?” / “Could you repeat that?”       |\n",
    "| **aa**     | Accept / Agree                      | “That’s true.”                             |\n",
    "| **sd@**    | Statement continuation (multi-turn) | “And then we went to the park.”            |\n",
    "| **t1**     | Self-Talk                           | “Let’s see…” / “Hmm…”                      |\n",
    "| **t3**     | Segment Other                       | (Speaker changes topic)                    |\n",
    "| **x**      | Non-verbal / Uninterpretable        | “[laughter]” / “[noise]”                   |\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "708ddb058892999a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we want to also train a simple classifier, to predict the dialogue acts based on the utterance text. For that we first need to create feature vectors from the utterance text. We will use a bag-of-words representation for that. Convokit provides a Bag-of-Words transformer that can be used to create vectors from the text of utterances. \n",
    "--> initialize the BoWTransformer and add the vectors to the corpus"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9daa84d815c9ac7a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "you can now see that the utterances_dataframe has a new column, called \"vectors\". with utt.get_vector(\"bow_vector\") we can retrieve the vector representation for an utterance. For can now use any scikit-learn classifier and try to predict dialogue acts based on the bag-of-words representation. Note: training the classifier might take a while on you local machine. If it takes too long, only use a subset of the dataset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "732d50ebc2015158"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# you can now see that the utterances_dataframe has a new column, called \"vectors\". with utt.get_vector(\"bow_ve\n",
    "swbd_corpus_utterances = swbd_corpus.get_utterances_dataframe()\n",
    "swbd_corpus_utterances.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "860c2a8e248b6ab1",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "--> Look at the results of the model. How does the model perform? Which tags are predicted well? Which are not?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2bdfb669f4ea00c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "You have now a first idea of how to load data with convokit and extract features. Pick one of the following tasks\n",
    "(a) Use a classifier trained to predict politeness based on the politeness features to predict it on a new dataset. You can either use the other portion of the corpus (stack-exchange-politeness-corpus) \n",
    "or \n",
    "(b) the switchboard corpus. This is spoken language, so a very different domain / genre. \n",
    "Inspect the predictions on a subset of 20 utterances. Do they make sense? What is the classifier missing?\n",
    "--> in general, this is a rather simple classifier. How do you think the classifier could be improved? Is there any additional context, for example that could be taken into consideration?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "451681c423d8737"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c74aaf2beb9453ec"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
